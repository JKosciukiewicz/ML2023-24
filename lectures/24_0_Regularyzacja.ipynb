{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUM 2023-24 Regularyzacja"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Problem i cel\n",
    "* model jest budowany z wykorzystaniem dostępnych danych\n",
    "  * dostępnych danych jest zwykle zbyt mało i budowa modelu z reguły prowadzi do jednego z dwóch problemów\n",
    "    * __underfitting__ gdy model zbytnio uogólnia\n",
    "    * __overfitting__ gdy model jest zbyt szczegółowy i zbyt dokładnie dopasowuje się do dostępnych danych [overfitting](./23_Overfitting.ipynb)\n",
    "  * regularyzacja powinna poprawić __wynik na zbiorze testowym__, często kosztem danych treningowych\n",
    "\n",
    "<img style=\"float: right;\" src=\"ml_figures/function-space-reduction.png\" width=450>  \n",
    "    \n",
    "* regularyzacja może być\n",
    "  * dodaniem pewnej wiedzy wstępnej _a priori_ do modelu przez użycie założonego rozkładu parametrów\n",
    "    * to ogranicza __pojemność modelu__ jednocześnie ograniczając overfitting\n",
    "  * ograniczeniem przestrzeni funkcji, np. ograniczenie użytych wykładników w aproksymacji wielomianowej  * dowolną modyfikacją uczenia poprawiającą generalizację kosztem błędu uczenia (Ian Goodfellow)\n",
    "* generalnie regularyzacja jest związana z ograniczeniem liczby parametrów\n",
    "  * miary AIC (Akaike) i BIC (Bayesian) Information Criterion\n",
    "\n",
    "#### Bardzo ważna uwaga\n",
    "1. regularyzacja modyfikuje funkcję kosztu __tylko na zbiorze treningowym__\n",
    "2. na __zbiorze testowym__ sprawdzamy __oryginalną funkcję kosztu__ (i ew. inne metryki, np. accuracy)\n",
    "3. czy jest jasne, dlaczego należy tak robić?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Najpopularniejsze modele regularyzacji\n",
    "  * weight decay\n",
    "  * early stopping\n",
    "  * dropout\n",
    "  * batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejścia do uczenia\n",
    "* podstawy do podejść do uczenia w notebooku [MLE i MAP](./stat_04_Twierdzenie_Bayesa.ipynb)\n",
    "\n",
    "### Uczenie Maximum Likelihood Estimator (MLE)\n",
    "* Szukamy takiego $w_\\ast$, które zmaksymalizuje wartość liczbową likelihoodu:\n",
    "$$w_\\ast = \\underset{w}{\\arg\\max}\\;p\\,(D_{Tr}\\mid{}w)$$\n",
    "  * gdzie $w$ jest zestawem parametrów odpowiadającym przyjętej hipotezie\n",
    "  * MLE szuka najlepszych parametrów z obserwowanych przykładów\n",
    "  * w MLE funkcja kosztu estymuje jak rozkład predykcji modelu odpowiada rozkładowi danych uczących\n",
    "  * MLE jest **spójny**: wraz ze wzrostem liczby przykładów uczących poprawia się estymacja parametrów modelu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie Maximum a Posteriori (MAP)\n",
    "1. oznaczmy przez $w$ wektor wszystkich parametrów modelu\n",
    "2. oznaczmy przez $L_{MLE}$ funkcję kosztu negative mean log likelihood (z dokładnością do stałych)\n",
    "3. oznaczmy przez $L_{MAP}$ funkcję kosztu __negative mean log posterior__ (z dokładnością do stałych)\n",
    "  * definiujemy podobnie do $L_{MLE}$\n",
    "  * z tą różnicą, że zamiast likelihood weźmiemy posterior\n",
    "4. obliczmy $L_{MAP}$ korzystając ze wzoru Bayesa\n",
    "$$\\begin{align}\n",
    "p(w\\mid D_{Tr}) &= \\dfrac{p(D_{Tr}\\mid{}w)p(w)}{p(D_{Tr})} \\\\\n",
    "\\ln[p(w\\mid D_{Tr})] &= \\ln[p(D_{Tr}\\mid{}w)] + \\ln[p(w)] - \\overbrace{\\ln[p(D_{Tr})]}^{const} \\\\\n",
    "-\\dfrac{1}{N}\\ln[p(w\\mid D_{Tr})] &= -\\dfrac{1}{N}\\ln[p(D_{Tr}\\mid{}w)] -\\dfrac{1}{N}\\ln[p(w)] + const \\\\\n",
    "L_{MAP}(w) &= L_{MLE}(w) -\\dfrac{1}{N}\\ln[p(w)]\n",
    "\\end{align}$$\n",
    "  * w definicji pomijamy $const$\n",
    "    * zależny od liczby przykładów $N$ oraz od $p$ i niezależny od wartości $w$\n",
    "    * można pominąć, bo maksymalizujemy po zmiennej $w$\n",
    "5. prosta reguła na regularyzację metodą MAP\n",
    "  * weź funkcję kosztu MLE\n",
    "  * dodaj składnik $-\\dfrac{1}{N}\\ln[p(w)]$\n",
    "    * __zależny od parametrów modelu__ $w$\n",
    "    * __niezależny od danych treningowych__\n",
    "\n",
    "#### Uwaga\n",
    "1. $L_{MLE}$ to __średnia__ po $N$ przykładach\n",
    "2. w takim razie $\\ln[p(\\theta)]$ musi być podzielone przez $N$\n",
    "  * jeśli $N$ dąży do nieskończoności, to wpływ wiedzy a priori musi dążyć do zera\n",
    "3. niekiedy w literaturze $\\ln[p(\\theta)]$ nie jest dzielone przez $N$, ale wtedy funkcja kosztu to negative log likelihood, a nie negative __mean__ log likelihood\n",
    "  * oba przypadki są równoważne\n",
    "\n",
    "### Jak wybrać prior\n",
    "* mamy pełną dowolność w zdefiniowaniu $p(w)$\n",
    "  * ale tylko \"dobry\" prior pomoże w uczeniu\n",
    "  * np. trzeba uważać, aby prior nie był zero dla żadnej sensownej hipotezy\n",
    "* dobrze zdefiniować go tak, aby łatwo liczył się logarytm\n",
    "  * funkcja $\\exp$ w definicji gęstości — wtedy się wykasuje z logarytmem\n",
    "  * współrzędne $w$ to zmienne niezależne — wtedy $\\ln[p(w)] = \\sum_{t=1}^T\\ln[p(w)]$\n",
    "* ważne są problemy dokładności i stabilności obliczeń"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Złożoność modelu a jego generalizacja\n",
    "<img style=\"float: left;\" src=\"ml_figures/error-complexity.png\" width=440>\n",
    "\n",
    "* generalizacja opisuje skuteczność modelu na przykładach spoza zbioru uczącego $$Err_{tst}=E[L(Y, f(x))\\mid D_{tst}]$$\n",
    "* $err$ to średni loss na zbiorze uczącym $D_{Tr}$\n",
    "  * błąd na zbiorze uczącym niekoniecznie jest dobrym estymatorem generalizacji\n",
    "* rozkład błędu modelu $\\hat{f}$ na _bias_ i _wariancję_\n",
    "  * niech szumem modelu będzie $\\epsilon\\sim\\mathcal{N}(0,\\sigma)$\n",
    "$$\\begin{align*}\n",
    "Err(\\hat{f})&=E[(y-\\hat{f})^2]&=E[y^2]-2E[y\\hat{f}]+E[\\hat{f}^2]\\\\\n",
    "\\\\\n",
    "&\\textrm{gdzie poszczególne elementy}\\\\\n",
    "E[y^2]&=E[(f+\\epsilon)^2]=E[f^2]+2E[f\\epsilon]+\\epsilon^2\\\\\n",
    "&=E[f^2]+2E[f]\\cdot0+\\epsilon^2&=f^2+\\sigma^2\\\\\n",
    "\\\\\n",
    "&\\textrm{dla każdej zmiennej losowej zachodzi}\\\\\n",
    "Var(X)&=E[(X-E[X])^2]=E[X^2]-E[X]^2\\\\\n",
    "&\\textrm{stąd}\\\\\n",
    "E[\\hat{f}^2]&=&=Var(\\hat{f})+E[\\hat{f}]^2\\\\\n",
    "\\\\\n",
    "E[y\\hat{f}]&=E[(f+\\epsilon)\\hat{f}]\\\\\n",
    "&=E[f\\hat{f}]+E[\\epsilon\\hat{f}]&=fE[\\hat{f}]\\\\\n",
    "\\\\\n",
    "&\\textrm{podstawiając}\\\\\n",
    "Err[\\hat{f}]&=f^2+\\sigma^2-2E[\\hat{f}]+Var(\\hat{f})+E[\\hat{f}]^2\\\\\n",
    "&=f^2-2f{}E[\\hat{f}]+E[\\hat{f}]^2+\\sigma^2+Var(\\hat{f})\\\\\n",
    "&=(f-E[\\hat{f}])^2+\\sigma^2+Var(\\hat{f})&=Bias[\\hat{f}]^2+\\sigma^2+Var(\\hat{f})\n",
    "\\end{align*}$$\n",
    "  <img style=\"float: right;\" src=\"ml_figures/bias-variance-triangle.png\" width=400>\n",
    "\n",
    "  * $\\sigma^2$ jest nieredukowalnym składnikiem błędu, niemożliwym do usunięcia\n",
    "  * $Bias[\\hat{f}]^2$ określa o ile średnia przybliżeń różni się od prawdziwej średniej\n",
    "  * $Var(\\hat{f})$ jest wariancją modelu $\\hat{f}$, oczekiwaną zmiennością funkcji wokół jej średniej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularyzacja L2 (weight decay)\n",
    "1. niech priorem będzie rozkład normalny\n",
    "  * zakładamy, że $w_t\\sim\\mathcal{N}(0,\\sigma^2)=\\dfrac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\dfrac{1}{2}\\left(\\dfrac{w_t}{\\sigma}\\right)^2\\right)$ dla $t\\in\\{1,\\ldots,T\\}$\n",
    "  * współrzędne $w$ są a priori niezależne\n",
    "$$\\begin{align}\n",
    "\\ln[p(w)] &= \\sum_{t=1}^T\\ln[p(w_t)] \\\\\n",
    "&= \\sum_{t=1}^T \\ln[1/\\sigma] + \\ln[1/\\sqrt{2\\pi}] - \\dfrac{w_t^2}{2\\sigma^2} \\\\\n",
    "&= const - \\lambda \\sum_{t=1}^T w_t^2 \\\\\n",
    "&= const - \\lambda \\|w\\|^2 \\\\\n",
    "L_{MAP}(w) &= L_{MLE}(w) + \\dfrac{\\lambda}{N}\\|w\\|^2 \n",
    "\\end{align}$$\n",
    "2. $const$ zależy tylko od $T$ i $\\sigma$, możemy pominąć przy optymalizacji gradientowej $w$\n",
    "3. parametr $\\lambda$ może być dowolną dodatnią liczbą rzeczywistą\n",
    "  * możemy wybrać dowolną liczbę, ponieważ możemy wybrać dowolne $\\sigma$\n",
    "    * czy widać, w jaki sposób $\\lambda$ zależy od $\\sigma$?\n",
    "    * co się stanie, jeśli wybierzemy ujemne $\\lambda$?\n",
    "  * gdy $\\lambda\\to 0$, to $L_{MAP}\\to L_{MLE}$\n",
    "    * jak zmienia się wtedy prior? jaka jest jego \"granica\"?\n",
    "    * czy to jest zgodne z naszymi oczekiwaniami? \n",
    "4. efekt regularyzacji L2\n",
    "  * ograniczenie sumy __kwadratów__ współrzędnych\n",
    "  * duże (na moduł) wartości $\\theta_t$ są bardzo kosztowne\n",
    "    * stąd nazwa __weight decay__\n",
    "      * uwaga na terminologię - w literaturze \"weight decay coefficient\" może oznaczać $\\lambda$ lub $2\\lambda$\n",
    "  * jeśli działanie fragmentu modelu zależy (w przybliżeniu) od __sumy__ $M$ współrzędnych $w_{t_1}, \\ldots, w_{t_M}$, to model nauczy się tam (w przybliżeniu) równych wartości liczbowych\n",
    "5. Weight decay wpływa na _efektywną_ liczbę parametrów\n",
    "  * parametry nieistotne dla modelu powinny być redukowane do zera\n",
    "    * L2 (sfera na układzie współrzędnych wag) redukuje pojedyncze wagi bardziej równomiernie\n",
    "    * L1 (wielościan z rogami na wagach) robi to bardziej nierównomiernie redukując bardziej nieistotne wagi bardziej\n",
    "      * jest \n",
    "  * efektyna liczba parametrów jest zwykle określona przez $$df(\\lambda)=\\sum_k\\dfrac{\\theta_k}{\\theta_k+\\lambda}$$ gdzie $\\theta_k$ to wartości własne macierzy Hesjanu funkcji kosztu $\\dfrac{\\nabla^2{}L(w)}{\\nabla{}w\\nabla{}w^T}$, a więc duże $\\lambda$ redukuje bardziej (jak można się było spodziewać)\n",
    "6. regresja liniowa z regularyzacją L2 to tzw. __ridge regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inne popularne rodzaje regularyzacji typu MAP\n",
    "\n",
    "1. __regularyzacja L1__ (__lasso__)\n",
    "$$L_{MAP}(w) = L_{MLE}(w) + \\dfrac{\\lambda}{N}\\|w\\|$$\n",
    "  * norma L1 zamiast normy L2\n",
    "  * odpowiada innemu priorowi\n",
    "    * podobnie jak w przypadku regresji liniowej - MSE vs MAE\n",
    "  * jeśli działanie fragmentu modelu zależy w przybliżeniu od sumy $M$ współrzędnych $w_{t_1}, \\ldots, w_{t_M}$, to modelowi opłaca się ustawić na 0 wszystkie $M-1$ współrzędnych poza jedną najistotniejszą\n",
    "    * regularyzacja L1 zachęca do uczenia __rzadkiego__ (_sparse_) wektora $w$\n",
    "    * zwiększa __interpretowalność__ - łatwiej przeanalizować kilka najistotniejszych współrzędnych\n",
    "\n",
    "2. połączenie L1 i L2 (__elastic net__)\n",
    "$$L_{MAP}(w) = L_{MLE}(w) + \\dfrac{\\lambda_1}{N}\\|w\\| + \\dfrac{\\lambda_2}{N}\\|w\\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularyzacja w praktyce\n",
    "\n",
    "1. zazwyczaj wystarczy użyć L2\n",
    "2. należy przetestować wiele różnych $\\lambda$ (nauczyć kilka modeli)\n",
    "3. można dobierać różne $\\lambda$ dla różnych współrzędnych\n",
    "  * np. różne $\\lambda$ dla różnych warstw sieci neuronowej\n",
    "  * ale jeśli to nie ma dobrego uzasadnienia, to zazwyczaj szkoda na to czasu\n",
    "4. powyższe regularyzacje zbliżają $w$ do zera\n",
    "  * np. sieciach neuronowych ustawienie wszystkich wag na 0 z reguły sprawi, że klasyfikator zwróci rozkład jednostajny, a regressor zero \n",
    "  * można oczywiście zrobić inaczej, np. użyć $\\sum_{t=1}^T (w_t - 1)^2$\n",
    "    * ale musimy mieć dobre uzasadnienie, że wszystkie współrzędne powinny wynosić w przybliżeniu 1\n",
    "    * zazwyczaj nie mamy\n",
    "5. można definiować własne regularyzacje\n",
    "  * pomysłowe regularyzacje mogą znacznie poprawić uczenie modelu\n",
    "  * nie trzeba przejmować się, czy odpowiadają jakiemukolwiek priorowi\n",
    "    * w najgorszym razie model nie zadziała, ale warto dlaczego\n",
    "    <!-- * warto rozumieć związek regularyzacji L2 oraz L1 z priorem ;-) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niezmienniki (inwariancje)\n",
    "* jeśli dla wielu wzorów predykcje nie mają się zmieniać, to odpowiada _wbudowywaniu niezmienników_ (_inwariancji_)\n",
    "  * szczególnie w rozpoznawaniu wzorców (translacje, obroty), czy dźwięków (np. głośność)\n",
    "  * przy odpowiedniej liczbie wzorców model może nauczyć się niezmienników\n",
    "    * można dodać odpowiednią liczbę powtórzeń przykładów odpowiednio zmodyfikowanych (augmentacje)\n",
    "    * dzielone wagi oraz tzw. pooling, jak w przypadku sieci konwolucyjnych, mogą być przykładem wbudowanych do architektury sieci niezmienników\n",
    "* niezmienniki są modelem wykorzystywanym w tzw. uczeniu ustawicznym (ciągłym, ang. continual learning)\n",
    "  * model uczy się szeregu następujących po sobie problemów\n",
    "  * po nauczeniu problemu $X_k$, pojawia się kolejny $X_{k+1}$\n",
    "  * algorytm uczący **nie ma już dostępu** do danych $X_k$\n",
    "  * wprowadzenie niezmienników odpowiada temu, by predykcje dla przykładów z $X_k, X_{k-1},\\dots$ pozostały bez zmian\n",
    "  * to jest bardzo trudne zadanie, ale aktualne\n",
    "* wiele potrzebnych augmentacji dla standardowych problemów jest dostepnych w bibliotekach, np. `torchvision.transforms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "* podobnie jak w przypadku zależności błędu uczącego i generalizacji w zależności od złożoności modelu, jest on zależny od długości uczenia (liczby epok)\n",
    "  * model wraz z liczbą epok staje się coraz bardziej 'dopasowany', a stąd i złożony\n",
    "  * pewnym rozwiązaniem może być wcześniejsze zatrzymanie uczenia\n",
    "  * wymaga wielu prób i zapamiętywania modeli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
