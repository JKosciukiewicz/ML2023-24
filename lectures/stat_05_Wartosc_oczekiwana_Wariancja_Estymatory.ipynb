{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUM 2023-24 Wartość oczekiwana, wariancja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartość oczekiwana\n",
    "\n",
    "* Wartość oczekiwana zmiennej losowej $X$ to \"średnia wartość\", jaką przyjmuje ta zmienna. Chodzi nam o średnią ważoną, gdzie wagi to prawdopodobieństwa zadane przez $X$.\n",
    "  * indeks górny __nie oznacza tu potęgowania__, ale kolejne wartości zmiennej $X$.\n",
    "  * Jeśli rozkład $X$ jest dyskretny na zbiorze $\\{x^1, x^2, \\ldots x^K\\}$, to wartość oczekiwana zdefiniowana jest jako\n",
    "$$\\mathbb{E}X := p(X=x^1)\\cdot x^1 + \\ldots + p(X=x^K)\\cdot x^K = \\sum_{k=1}^K p(X=x^k)\\cdot x^k$$\n",
    "  * Jeśli zbiór wartości $X$ jest nieskończony, to mamy\n",
    "$$\\mathbb{E}X := \\sum_{k=1}^\\infty p(X=x^k)\\cdot x^k$$\n",
    "  * W wypadku zmiennej ciągłej suma zamienia się na całkę, a prawdopodobieństwo $p$ na gęstość rozkładu $f$\n",
    "$$\\mathbb{E}X := \\int_{\\mathbb{R}} f(x)\\cdot x\\, dx$$\n",
    "\n",
    "* Wartość oczekiwana to __nie__ jest wartość, która pojawia się najczęściej.\n",
    "  * Jeśli np. $X$ opisuje rzut symetryczną sześcienną kostką, to wartość oczekiwana wynosi $\\mathbb{E}X = 3,5$ - taka wartość nigdy nie zostanie wylosowana.\n",
    "* W wypadku zmiennej wielowymiarowej jest to \"średni wektor\", którego współrzędne to wartości oczekiwane współrzędnych.\n",
    "  * Suma zamienia się na sumę wektorów, całka na całkę wielowymiarową.\n",
    "\n",
    "* $X$ to __zmienna losowa__, ale $\\mathbb{E}X$ to po prostu __liczba__ (lub wektor).\n",
    "* Istnieją zmienne losowe, które nie mają wartości oczekiwanej (suma nieskończona jest rozbieżna, funkcja $f(x)\\cdot x$ nie jest całkowalna)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Warunkowa wartość oczekiwana\n",
    "\n",
    "* Jeśli mamy dwie zmienne losowe $X, Y$, to możemy zapytać o wartość oczekiwaną $X$, jeśli $Y$ jest ustalone i np. równe $a$.\n",
    "* Niech $p(x,y)$ będzie rozkładem łącznym w przypadku dyskretnym, a $f(x,y)$ gęstością w przypadku ciągłym.\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}(X \\mid Y=a) &= \\dfrac{\\sum_{k=1}^\\infty p(X=x^k, Y=a)\\cdot x^k}{p(Y=a)}\\\\ \n",
    "&= \\sum_{k=1}^\\infty p(X=x^k \\mid Y=a)\\cdot x^k\\\\\n",
    "\\mathbb{E}(X \\mid Y=a) &= \\dfrac{\\int_{\\mathbb{R}} f(x,a)\\cdot x\\, dx}{\\int_{\\mathbb{R}} f(x,a)\\, dx}\n",
    "\\end{align}$$\n",
    "  * Jeśli zmienne są niezależne, to $\\mathbb{E}(X\\mid Y) = \\mathbb{E}X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wariancja\n",
    "\n",
    "* Wariancja zmiennej $X$ mówi nam, jak bardzo ta zmienna różni się od swojej wartości oczekiwanej.\n",
    "  * Im mniejsza wariancja, tym mniejsza ta różnica.\n",
    "* Wariancja zmiennej $X$ to wartość oczekiwana zmiennej $(X-\\mathbb{E}X)^2$, czyli\n",
    "$$Var(X) := \\mathbb{E}((X - \\mathbb{E}X)^2)$$\n",
    "\n",
    "* Co w powyższym wzorze jest zmienną losową, a co liczbą (wektorem)?\n",
    "\n",
    "* Istnieją zmienne losowe, które nie mają wariancji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estymatory\n",
    "\n",
    "* Niech istnieje pewien parametr, którego wartość jest ustalona, ale nieznana.\n",
    "  * Wartość tego parametru ma wpływ na dane, które obserwujemy.\n",
    "  * Chcemy _wyestymować_ ten parametr, korzystając z obserwacji.\n",
    "\n",
    "* To, co różni estymowanie od podejścia bayesowkiego, to założenie, że chcemy otrzymać jedną konkretną wartość parametru.\n",
    "  * Nie chcemy modelować naszej niepewności na jego temat.\n",
    "\n",
    "* Estymator parametru $\\theta$ to taka funkcja, która przyjmuje na wejściu $N$ obserwacji i zwraca estymowaną wartość $\\widehat\\theta$, która w jakimś sensie jest \"najlepszym przybliżeniem\" prawdziwej nieznanej wartości $\\theta$.\n",
    "\n",
    "* Najlepiej zrozumieć koncepcję estymatora na przykładach.\n",
    "\n",
    "### Estymator wartości oczekiwanej\n",
    "\n",
    "* Załóżmy, że $x^1, x^2, \\ldots, x^N$ to ciąg sampli z $X$. Niech\n",
    "$$ \\theta := \\mathbb{E}X $$\n",
    "\n",
    "  * Wtedy możemy zdefiniować estymator\n",
    "$$ \\widehat\\theta := \\dfrac{x^1 + x^2 + \\ldots + x^N}{N} $$\n",
    "\n",
    "* Czyli twierdzimy, że średnia obserwacji dobrze przybliża wartość oczekiwaną $X$.\n",
    "\n",
    "### Estymatory wariancji\n",
    "\n",
    "* Załóżmy, że $x^1, x^2, \\ldots, x^N$ to ciąg sampli z $X$. Niech\n",
    "$$ \\theta := Var(X) = \\mathbb{E}((X - \\mathbb{E}X)^2) $$\n",
    "\n",
    "  * Niech\n",
    "$$ S := \\dfrac{x^1 + x^2 + \\ldots + x^N}{N} $$\n",
    "  * Wtedy możemy zdefiniować tzw. __obciążony__ estymator wariancji\n",
    "$$ \\widehat\\theta := \\dfrac{1}{N}\\sum_{n=1}^N (x_n - S)^2 $$\n",
    "oraz __nieobciążony__ estymator wariancji\n",
    "$$ \\widehat\\theta := \\dfrac{1}{N-1}\\sum_{n=1}^N (x_n - S)^2 $$\n",
    "\n",
    "* Estymatory obciążone mają __niezerowy bias__.\n",
    "  * Estymatory nieobciążone są lepsze. Wrócimy jeszcze do dyskusji na temat estymatorów obciążonych przy okazji omawiania _bias-variance trade off_.\n",
    "\n",
    "### Maximum Likelihood Estimator (MLE)\n",
    "\n",
    "* MLE jest, zgodnie z nazwą, estymatorem. Zgodnie z definicją\n",
    "$$\\widehat\\theta = \\underset{\\theta^k}{\\arg\\max}\\;p\\,(D_{Tr}\\mid\\theta=\\theta^k)$$\n",
    "\n",
    "  * W tym wypadku $\\theta$ ma być \"prawdziwą\" hipotezą na temat danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estymator wartości oczekiwanej - uwaga\n",
    "\n",
    "* Niech $X$ ma rozkład dyskretny na zbiorze $\\{x^1, \\ldots x^K\\}$, a $y^1, \\ldots, y^N$ będzie ciągiem sampli z tego rozkładu.\n",
    "  * Wartość oczekiwana $X$ jest zdefiniowana jako\n",
    "$$\\mathbb{E}X := p(X=x^1)\\cdot x^1 + \\ldots + p(X=x^K)\\cdot x^K$$\n",
    "\n",
    "natomiast estymator wartości oczekiwanej to\n",
    "$$ \\widehat\\theta := \\dfrac{1}{N}y^1 + \\ldots + \\dfrac{1}{N}y^N $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytanie\n",
    "\n",
    "* Twierdzimy, że ten estymator jest dobrym przybliżeniem\n",
    "  *  takim razie, dlaczego w drugim przypadku wszystkie wagi są równe $\\frac{1}{N}$?\n",
    "  *  Dlaczego np. nie użyć estymatora jak poniżej?\n",
    "$$ \\widehat\\theta := p(y^1)\\cdot y^1 + \\ldots + p(y^N)\\cdot y^N $$\n",
    "\n",
    "  * A jak sprawa wygląda w wypadku rozkładów ciągłych?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
