{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUM 2023-24 Optymalizator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sieć neuronowa (NN)\n",
    "<img style=\"float: right;\" src=\"ml_figures/simple_nn.png\" width=450>\n",
    "\n",
    "* NN jest wielowymiarową funkcją (zwykle) nieliniową $F:X\\longrightarrow Y$\n",
    "  * dla funkcji zdefiniowana jest różniczkowalna funkcja kosztu $L:Y\\times F(X)\\longrightarrow \\mathbb{R}$\n",
    "  * uczenie odbywa się w pętli dla optymalizacji parametrów\n",
    "  * problem MNIST (niespecjalnie dobre rozwiązanie!)\n",
    "* w Pytorch sieć neuronowa jest zrealizowana jako [__graf obliczeniowy__](./12_Graf_obliczen.ipynb)\n",
    "<img style=\"float: right;\" src=\"ml_figures/comp_graph.png\" width=400>\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):    \n",
    "    # (kod ze tutoriala `Pytorch`)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "```\n",
    "  * do tego metoda `forward` obliczająca wartość aktywacji\n",
    "```python\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "```\n",
    "  * `model = NeuralNetwork()` utworzy obiekt tej sieci\n",
    "  * pętla ucząca\n",
    "  ```python\n",
    "  def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "  ```\n",
    "  * i wykonanie\n",
    "  ```python\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  epochs = 10\n",
    "  for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "  ```\n",
    "  * funkcja kosztu `loss_fn` musi brać pod uwagę, jakie wartości zwracane są przez model\n",
    "    * tutaj model zwraca `logits` z przedziału $[-\\infty, +\\infty]$, stąd `CrossEntropyLoss(x, y)`\n",
    "    $$L(x, y) = -\\sum_k\\log\\frac{\\exp x_k}{\\sum_i\\exp x_i}y_k$$\n",
    "  * predykcja modelu\n",
    "    ```python\n",
    "    logits = model(X)\n",
    "    pred_proba = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_proba.argmax(1)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Gradientowa__ i __iteracyjna__ minimalizacja $L$\n",
    "* $w$ - wektor wszystkich parametrów modelu rozpoczynając od $w_0$\n",
    "* $w_t$ - wartość parametrów po $t$ krokach (po czasie $t$)\n",
    "* krok w czasie $t$ $\\Delta _t := w_t-w_{t-1}$\n",
    "* $L$ - _różniczkowalna_ funkcja kosztu\n",
    "* $\\gamma$ - __learning rate__\n",
    "    * kontroluje szybkość uczenia\n",
    "    * może zmieniać się w czasie $\\gamma_t$\n",
    "* Wartość $L$ zależy od:\n",
    "  * danych treningowych i wektora $\\theta$\n",
    "  * architektury modelu\n",
    "  * być może jeszcze innych stałych\n",
    "* Optymalizujemy tylko $w$, będziemy pisać w skrócie $L(w_t)$.\n",
    "* $L$ zwraca wartość: zakładamy, że umiemy policzyć gradient $\\nabla L(w)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Materiały dodatkowe -->\n",
    "\n",
    "<!-- http://ruder.io/optimizing-gradient-descent/index.html -->\n",
    "<!--  -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 😏Gradient Descent\n",
    "\n",
    "### Update\n",
    "<img style=\"float: right;\" src=\"ml_figures/Optimizery_steepest_descent.png\" width=400>\n",
    "\n",
    "1. $w_{t+1}=\\theta_{t} - \\gamma\\nabla L(w_{t})$\n",
    "2. $-\\nabla L(w_t)$ to kierunek najszybszego spadku $L$\n",
    "  * jednak $-\\nabla L(w_t)$ __nie wskazuje__ optymalnego kierunku $w$\n",
    "3. wektor gradientu $\\nabla L(w_t)$ jest prostopadły do hiperpłaszczyzny stycznej do powierzchni o równych wartościach funkcji kosztu (_isosurface_) w miejscu $w_t$\n",
    "4. zmniejszenie $L$ odpowiada __co najmniej__ rozwartemu kątowi między $\\nabla\\theta^{(t)}$ a $\\Delta\\theta^{(t)}$\n",
    "5. learning rate $\\gamma$\n",
    "    * mała wartość — spowalnia uczenie\n",
    "    * duża wartość — powoduje __oscylacje__, problem ze zbieżnością\n",
    "6. dlaczego nie normalizujemy $\\nabla L(w_t)$?\n",
    "    * duża wartość gradientu to __duża lokalna zmienność $L$__ - powinniśmy robić __mniejsze kroki__ (precyzyjniej)\n",
    "    * mała wartość gradientu to __mała lokalna zmienność $L$__ - powinniśmy robić __większe kroki__ (aby szybciej opuścić __plateau__)\n",
    "7. wariant GD ze zmiennym w czasie $\\gamma$\n",
    "  * malejący w stosunku odwrotnym do kroku uczenia $t$\n",
    "    * warunki konieczne osiągnięcia optymalnego $\\gamma$ (przy jakich założeniach? uwaga na __lokalne minima__)\n",
    "        $$\\begin{align}\\sum_t\\gamma_t^2\\lt\\infty\\\\\\sum_t\\gamma_t=\\infty\\end{align}$$\n",
    "8. niech $\\gamma_{opt}$ będzie _optymalna_\n",
    "  * $\\gamma<\\gamma_{opt}$: uczenie będzie postępować zbyt małymi krokami\n",
    "  * $\\gamma=\\gamma_{opt}$: uczenie powinno być jednokrokowe (funkcja $L$ wypukła)\n",
    "  * $\\gamma>\\gamma_{opt}$: duże oscylacje uczenia jednak zbieżne do minimum\n",
    "  * $\\gamma\\geq2\\gamma_{opt}$: niebezpieczeństwo wyskoczenia i rozbieżności w uczeniu\n",
    "9. zwykle jednak w praktyce najszybsza zbieżność jest osiągana przy $\\gamma$ bliskim tej dla rozbieżności\n",
    "  * należy używać jak największej $\\gamma$ ale nie większej ;-)\n",
    "\n",
    "__GD jest najgorszą możliwą metodą optymalizacji__ 😏 😒 😩 😒 😞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent SGD\n",
    "$$w_{t+1}=w_t-\\gamma_t\\nabla{}L_i(w_t)$$\n",
    "gdzie indeks $i$ wskazuje na wybrany losowo przykład (z rozkładu równomiernego)\n",
    "* to __najlepsza metoda optymalizacji__ dlaczego?!?!\n",
    "* można spojrzeć na SGD jako GD z szumem\n",
    "  * przy uczeniu wielu przykładów jest duży stopień _redundancji_ przykładów, chociażby wiele tych samych cyfr w MNIST\n",
    "  * w początkowych krokach szum jest niewielki w porównaniu do informacji w gradiencie\n",
    "    * krok SGD jest równie dobry jak krok GD\n",
    "  * szum może zabezpieczyć przed wpadnięciem do lokalnego (niepoprawnego) minimum\n",
    "    * to przypomina _annealing_ - uczenie z _explicite_ dodanym stochastycznym szumem malejącym wraz z postępem uczenia\n",
    "  * SGD jest drastycznie szybsze od GD i można wykonać tym samym kosztem tysiące kroków zamiast jednego kroku GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametr stałej uczenia\n",
    "* optymalna wartość stałej uczenia zależy od wielkości zbioru uczącego,\n",
    "* a także od od wielkości batchu\n",
    "\n",
    "[wizualizacja [deeplearning.ai]](https://www.deeplearning.ai/ai-notes/optimization/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batches\n",
    "$$w_{t+1}=w_t-\\gamma_t\\frac{1}{|B_i|}\\sum_{i\\in{}B_i}\\nabla{}L_i(w_t)$$\n",
    "* istotny jest element $1/|B_i|$ \n",
    "* w oczywisty sposób można lepiej wykorzystać sprzęt, w szczególności GPU\n",
    "* bardzo przydatne dla urównoleglenia uczenia\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "<img style=\"float: right;\" src=\"ml_figures/momentum-nag.png\" width=450>\n",
    "\n",
    "* SGD z momentum to SGD z dodanym efektem ciężkiej kuli podążającej dotychczasowym kierunkiem\n",
    "$$\\begin{align*}\n",
    "p_{t+1} &= \\nabla L_i(w_t) + \\beta p_t\\\\\n",
    "w_{t+1}&=w_t - \\gamma{}p_{t+1}=w_t - \\gamma{}\\nabla L_i(w_t) - \\gamma\\beta{}p_t\\\\\n",
    "&\\textrm{ponieważ}\\\\\n",
    "p_t&=\\nabla L_i(w_{t-1}) + \\beta p_{t-1}\\\\\n",
    "w_t&=w_{t-1} - \\gamma{}p_t\\\\\n",
    "-\\gamma{}p_t&=w_t-w_{t-1}\\\\\n",
    "&\\textrm{stąd}\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t\\nabla L_i(w_t) + \\beta(w_t-w_{t-1})\n",
    "\\end{align*}$$\n",
    "gdzie ostatni składnik jest dodatkowy względem SGD\n",
    "<img style=\"float: right;\" src=\"ml_figures/opt2.gif\" width=450>\n",
    "\n",
    "0. Krok staje się kombinacją poprzedniego kierunku i negatywnego gradientu\n",
    "1. Analogia do kulki toczącej się ze wzgórza, $\\beta$ to tarcie lub opór powietrza\n",
    "2. __Pamięć__\n",
    "    * wzajemnie wzmacniają się kroki w __istotnym kierunku__ i kierunek nie jest zmieniany natychmiast\n",
    "    * __oscylacje__ są tłumione i uśredniają się do małej wartości\n",
    "    * mniejsze spowolnienie na __plateau__, jeśli \"kulka\" była rozpędzona\n",
    "3. wartości hiperparametru $\\beta=0.9$ lub $\\beta=0.99$ sprawdzają się prawie zawsze\n",
    "   * zwykle zwiększenie $\\beta$ powinno skutkować _zmniejszeniem_ $\\gamma$ dla utrzymania zbieżności\n",
    "\n",
    "To jest ten _free lunch_, którego podobno niema 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov accelerated gradient NAG\n",
    "\n",
    "  * NAG jest wyjściem o jeden krok do przodu i wzięciem wartości w miejscu, gdzie optymalizator dopiero się znajdzie\n",
    "$$\\begin{align}\n",
    "p_{t+1} &= \\nabla L_i(w_t) +  \\beta{}p_t\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t(\\nabla L_i(w_t)+\\beta{}p_{t+1})\\\\\n",
    "       &=w_t - \\gamma_t(1+\\beta)\\nabla L_i(w_t) - \\gamma_t\\beta^2p_t\n",
    "\\end{align}$$\n",
    "    * zgrubne oszacowanie _prawdopodobnego_ nowego $w{t+1}=w_t-\\gamma_t p_{t+1}$\n",
    "    * gradient liczony w nowym miejscu — rozszerzenie momentum z _ekstrapolacją_\n",
    "* większe $\\beta$ powoduje wolniejszą reakcję na zmianę powierzchni błędu\n",
    "* można pokazać, że NAG przyspiesza uczenie dla wypukłych funkcji i (bardzo) dobrze dobranych parametrów\n",
    "* momentum też przyspiesza, ale jedynie na kwadratowych powierzchniach funkcji błędu\n",
    "* nie ma teoretycznych wyników pokazujących przyspieszenie NAG dla sieci neuronowych, chociaż często takie obserwujemy\n",
    "  * dla sieci neuronowych zwykle NAG zachowuje się równie dobrze jak momentum\n",
    "* przyspieszenie oraz wygładzanie szumu wpływa na lepsze zachowanie algorytmów momentum i NAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD a Momentum a NAG\n",
    "<img style=\"float: right;\" src=\"ml_figures/opt2.gif\" width=450>\n",
    "$$\n",
    "\\begin{alignat}{5}\n",
    "w_{t+1}&=w_t-\\gamma_t\\nabla{}L_i(w_t)\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t{}\\nabla L_i(w_t) + \\beta(w_t-w_{t-1})\\\\\n",
    "w_{t+1}&=w_t - \\gamma_t(1+\\beta)\\nabla L_i(w_t) - \\gamma\\beta^2p_t\n",
    "\\end{alignat}\n",
    "$$\n",
    "\n",
    "[wizualizacje algorytmów [deeplearning.ai]](https://www.deeplearning.ai/ai-notes/optimization/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
